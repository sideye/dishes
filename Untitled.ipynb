{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This is good shit\"\n",
    "sentence2 = \"Textblob is amazingly simple to use. What great fun!\"\n",
    "sentence3 = \"The boba was absolutely the worst thing I've ever had.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sentiment(polarity=-0.4, subjectivity=0.95),\n",
       " {'neg': 0.327, 'neu': 0.673, 'pos': 0.0, 'compound': -0.6573})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "s2 = TextBlob(sentence3)\n",
    "s2.sentiment, vader_analyzer.polarity_scores(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vietnamese coffee 0.19025346599858536\n",
      "combination sandwich 0.2439224819746897\n",
      "grilled chicken sandwich 0.12571701994105405\n",
      "meatball sandwich 0.13164094871246668\n",
      "grilled pork sandwich 0.24189355459464304\n",
      "lemongrass tofu sandwich 0.2658984154728622\n",
      "lemongrass beef sandwich 0.25460878561915046\n",
      "spring rolls 0.19661369464764744\n",
      "vermicelli noodle 0.397675\n",
      "rice plate 0.17619365956622118\n"
     ]
    }
   ],
   "source": [
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "for file_path in os.listdir('./extracted_dish_info/')[:1]:\n",
    "    dishes = {}\n",
    "    with open('./extracted_dish_info/{}'.format(file_path), \"r+\") as fp:\n",
    "        inp = json.load(fp)\n",
    "    \n",
    "    # Part 1: determine sentiment of each dish\n",
    "    for dish in inp:\n",
    "        dish_sent_sum = 0 \n",
    "        for review in inp[dish]:\n",
    "            excerpts = review['excerpts']\n",
    "            excerpt_weight = 1\n",
    "            sent_sum = 0\n",
    "            for excerpt in excerpts:\n",
    "                vader_sent = vader_analyzer.polarity_scores(excerpt)\n",
    "                text_blob_sent = TextBlob(excerpt).sentiment\n",
    "                overall_sent = 0.15*vader_sent['neg'] + 0.15*vader_sent['pos'] + 0.25 * vader_sent['compound'] + 0.45 * text_blob_sent.polarity\n",
    "                sent_sum += excerpt_weight * overall_sent\n",
    "            review_sent = sent_sum / len(excerpts) * math.log(5+len(excerpts) - 1, 5)\n",
    "            dish_sent_sum += review_sent\n",
    "        if inp[dish]:\n",
    "            dish_sent = dish_sent_sum / len(inp[dish])\n",
    "            print(dish, dish_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camarones 0.14641280017348338\n",
      "menudo -0.0007794956629178174\n"
     ]
    }
   ],
   "source": [
    "dishes = {}\n",
    "with open('./extracted_dish_info/el-farolito-san-francisco.json'.format(file_path), \"r+\") as fp:\n",
    "    inp = json.load(fp)\n",
    "\n",
    "# Part 1: determine sentiment of each dish\n",
    "for dish in inp:\n",
    "    dish_sent_sum = 0 \n",
    "    for review in inp[dish]:\n",
    "        excerpts = review['excerpts']\n",
    "        excerpt_weight = 1\n",
    "        sent_sum = 0\n",
    "        for excerpt in excerpts:\n",
    "            vader_sent = vader_analyzer.polarity_scores(excerpt)\n",
    "            text_blob_sent = TextBlob(excerpt).sentiment\n",
    "            overall_sent = 0.15*vader_sent['neg'] + 0.15*vader_sent['pos'] + 0.25 * vader_sent['compound'] + 0.45 * text_blob_sent.polarity\n",
    "            sent_sum += excerpt_weight * overall_sent \n",
    "            excerpt_weight = excerpt_weight * 0.8\n",
    "        review_sent = sent_sum / len(excerpts) * math.log(5+len(excerpts) - 1, 5) # upweight longer reviews\n",
    "        dish_sent_sum += review_sent\n",
    "    if inp[dish]:\n",
    "        dish_sent = dish_sent_sum / len(inp[dish])\n",
    "        print(dish, dish_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
