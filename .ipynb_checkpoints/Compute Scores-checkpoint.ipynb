{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This is good shit\"\n",
    "sentence2 = \"Textblob is amazingly simple to use. What great fun!\"\n",
    "sentence3 = \"The boba was absolutely the worst thing I've ever had.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "for file_path in os.listdir('./extracted_dish_info/')[:1]:\n",
    "    dishes = {}\n",
    "    with open('./extracted_dish_info/{}'.format(file_path), \"r+\") as fp:\n",
    "        inp = json.load(fp)\n",
    "    \n",
    "    rankings = {'dishes': [], 'dish_sent':[], 'overall_sent': [], 'rating':[], 'dish_pop':[]}\n",
    "\n",
    "    # Part 0: clean out non excerpted dishes\n",
    "    to_remove = []\n",
    "    for dish in inp:\n",
    "        if not inp[dish]:\n",
    "            to_remove.append(dish)\n",
    "    for item in to_remove:\n",
    "        del inp[item]\n",
    "    \n",
    "    # Part 1: determine sentiment of each dish\n",
    "    category_scores = {}\n",
    "    for dish in inp:\n",
    "        category_scores[dish] = {}\n",
    "    \n",
    "    \n",
    "    for dish in inp:\n",
    "        dish_sent_sum = 0 \n",
    "        for review in inp[dish]:\n",
    "            excerpts = review['excerpts']\n",
    "            excerpt_weight = 1\n",
    "            sent_sum = 0\n",
    "            for excerpt in excerpts:\n",
    "                vader_sent = vader_analyzer.polarity_scores(excerpt)\n",
    "                text_blob_sent = TextBlob(excerpt).sentiment\n",
    "                overall_sent = 0.15*vader_sent['neg'] + 0.15*vader_sent['pos'] + 0.25 * vader_sent['compound'] + 0.45 * text_blob_sent.polarity\n",
    "                sent_sum += excerpt_weight * overall_sent\n",
    "            review_sent = sent_sum / len(excerpts) * math.log(5+len(excerpts) - 1, 5)\n",
    "            dish_sent_sum += review_sent\n",
    "        dish_sent = dish_sent_sum / len(inp[dish])\n",
    "        category_scores[dish]['dish_sentiment'] = dish_sent\n",
    "        \n",
    "        rankings['dishes'] = rankings['dishes'] + [dish]\n",
    "        rankings['dish_sent'] = rankings['dish_sent'] + [dish_sent]\n",
    "      \n",
    "    # Part 2: determine overall sentiment\n",
    "    for dish in inp: \n",
    "        overall_sent_sum = 0\n",
    "        for review in inp[dish]:\n",
    "            review_text = review['review']\n",
    "            vader_sent = vader_analyzer.polarity_scores(review_text)\n",
    "            text_blob_sent = TextBlob(review_text).sentiment\n",
    "            overall_sent = 0.15*vader_sent['neg'] + 0.15*vader_sent['pos'] + 0.25 * vader_sent['compound'] + 0.45 * text_blob_sent.polarity\n",
    "            overall_sent_sum += overall_sent\n",
    "        overall_sent = overall_sent_sum / len(inp[dish])\n",
    "        category_scores[dish]['overall_sentiment'] = overall_sent\n",
    "        \n",
    "        rankings['overall_sent'] = rankings['overall_sent'] + [overall_sent]\n",
    "    \n",
    "    # Part 3: rating\n",
    "    for dish in inp:\n",
    "        ratings = [r['rating'] for r in inp[dish]]\n",
    "        category_scores[dish]['avg_rating'] = sum(ratings)/len(ratings)\n",
    "        \n",
    "        rankings['rating'] = rankings['rating'] + [sum(ratings)/len(ratings)]\n",
    "    \n",
    "    # Part 4: dish popularity\n",
    "    for dish in inp:\n",
    "        category_scores[dish]['dish_popularity'] = len(inp[dish])\n",
    "        \n",
    "        rankings['dish_pop'] = rankings['dish_pop'] + [len(inp[dish])]\n",
    "    \n",
    "    # Part 5: restaurant popularity\n",
    "    restaurant_popularity = pd.read_json('./reviews/{}'.format(file_path), lines=True).shape[0]\n",
    "    for dish in inp:\n",
    "        category_scores[dish]['rest_popularity'] = math.log(restaurant_popularity,10)\n",
    "    \n",
    "    # COMBINE\n",
    "    # For now: do dish ranking through ranks. Will be changed in V2 when comparing dishes across restaurants\n",
    "    for key in rankings:\n",
    "        if key != 'dishes':\n",
    "            rankings[key] = pd.Series(rankings[key]).rank()\n",
    "    output_rankings = []\n",
    "    for dish_sent, overall_sent, rating, dish_pop in zip(rankings['dish_sent'], rankings['overall_sent'], rankings['rating'], rankings['dish_pop']):\n",
    "        score = dish_sent * 0.5 + overall_sent * 0.1 + rating * 0.2 + dish_pop * 0.2\n",
    "        output_rankings.append(score)\n",
    "        \n",
    "    output_rankings = pd.Series(output_rankings).rank()\n",
    "    \n",
    "    output = {}\n",
    "    for dish in inp:\n",
    "        output[dish] = {}\n",
    "    for dish, score, sentiment in zip(rankings['dishes'], output_rankings, rankings['dish_sent']):\n",
    "        output[dish]['overall_score'] = score\n",
    "        output[dish]['sentiment_score'] = sentiment\n",
    "            \n",
    "    with open('./output/{}'.format(file_path), \"w+\") as output_file:\n",
    "        json.dump(output, output_file)\n",
    "\n",
    "    \n",
    "# IDEA: BUILD NLP model based on review data solely. Train results col can be found in yelp review scores\n",
    "\n",
    "# names = rank_test['names']\n",
    "# for key in rank_test:\n",
    "#     rank_test[key] = pd.Series(rank_test[key]).rank()\n",
    "\n",
    "# fig, ax = plt.subplots(4,1)\n",
    "# ax[0].bar(names, rank_test['dishsent'])\n",
    "# ax[1].bar(names, rank_test['overallsent'])\n",
    "# ax[2].bar(names, rank_test['rating'])\n",
    "# ax[3].bar(names, rank_test['dish_pop'])\n",
    "# fig.set_size_inches((18,14))\n",
    "# [rank_test['dishsent'], rank_test['overallsent'], rank_test['rating'], rank_test['dish_pop']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
